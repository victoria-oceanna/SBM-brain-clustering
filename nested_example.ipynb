{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8beceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory:/home/daoutidi/shared/brain_transfer/\n",
      "Current threshold: 0.59\n",
      "Number of iterations set to 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 102.884961 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import graph_tool as gt\n",
    "from graph_tool import inference\n",
    "from pytictoc import TicToc\n",
    "from joblib import Parallel, delayed\n",
    "from readFile import *\n",
    "from SBMs import *\n",
    "import config\n",
    "\n",
    "#set global variables from config\n",
    "choose_run = config.choose_run\n",
    "threshold = config.threshold\n",
    "file_names = config.file_names\n",
    "iterations = config.iterations\n",
    "directory = config.loc\n",
    "\n",
    "#set up function for parallelization\n",
    "def obtain_nested_partition(i):\n",
    "    #choose run with lowest percent censored frames and adjust index\n",
    "    PC = int(choose_run['best_runs'][i]) - 1\n",
    "    \n",
    "    # load the data for that run\n",
    "    print(file_names[i])\n",
    "    adj = loadmat(directory + file_names[i])\n",
    "    \n",
    "    # select the correct connectivity matrix for best run\n",
    "    rmat = np.asarray(adj['RS_connectivity_raw'][0][PC]['xcorr'][0][0]['rmat'])\n",
    "    run = np.asarray(rmat[0][0])\n",
    "\n",
    "    # obtain nSBM partition\n",
    "    partition = np.asarray(nested_SBM(run, threshold, iterations))\n",
    "    return partition\n",
    "\n",
    "#initialize timing\n",
    "t = TicToc()\n",
    "t.tic()\n",
    "\n",
    "#set range for desired indices within full dataset\n",
    "start_index = 0\n",
    "end_index = 3\n",
    "\n",
    "#set number of available cores for parallelization\n",
    "cores = 3\n",
    "\n",
    "#parallelize according to number of available cores - verbose for job updates\n",
    "results = Parallel(n_jobs=cores, verbose = 30, timeout = 30000)(delayed(obtain_nested_partition)(i) for i in range(start_index,end_index))\n",
    "\n",
    "#end timing\n",
    "t.toc()\n",
    "\n",
    "#choose file name\n",
    "file_name = \"example_nested.csv\"\n",
    "\n",
    "#save results as csv - each row within csv file corresponds to a different subject and each column (of 1088) is the node of corresponding index\n",
    "np.savetxt(file_name, results, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f0b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd693a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "using_graph_tool",
   "language": "python",
   "name": "using_graph_tool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
